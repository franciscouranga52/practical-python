{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ja871rAui_Da"
   },
   "source": [
    "# Scraping Files from Websites "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwHrS-KJi_Dg"
   },
   "source": [
    "### You need to create a data set that tracks how many companies the <a href=\"https://www.sec.gov/litigation/suspensions.shtml\">SEC suspended</a> between 2019 and 1999. You find the data at:\n",
    "\n",
    "```https://www.sec.gov/litigation/suspensions.shtml```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_OAOaqLi_Dh"
   },
   "source": [
    "### We want to write a scraper that aggregates:\n",
    "\n",
    "* Date of suspension\n",
    "* Company name\n",
    "* Order\n",
    "* Release (the PDFs in the XX-YYYYY format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECK4Q7IOi_Di"
   },
   "source": [
    "# The Challenge?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQj34GvYi_Di"
   },
   "source": [
    "### Details are actually in PDFs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfkXDlQvi_Di"
   },
   "source": [
    "# Demo downloading files from websites "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyvf5HLGi_Dj"
   },
   "source": [
    "There are ```txt``` and ```pdf``` files on:\n",
    "\n",
    "```https://sandeepmj.github.io/scrape-example-page/pages.html```\n",
    "\n",
    "Do the following:\n",
    "\n",
    "1. Download all ```txt``` files.\n",
    "2. Download all ```pdf``` files.\n",
    "3. Download all files as one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "W1jQ2nQei_Dj"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from bs4 import BeautifulSoup  ## scrape info from web pages\n",
    "import requests ## get web pages from server\n",
    "import time # time is required. we will use its sleep function\n",
    "from random import randrange # generate random numbers\n",
    "\n",
    "# from google.colab import files ## code for downloading in google colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create function to handle our initial requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write function here\n",
    "def mkRequest (url):\n",
    "    '''\n",
    "    Takes a providad url and returns rreuquested response\n",
    "    '''\n",
    "    response = requests.get(url)\n",
    "    if 200 <= response.status_code < 400: #controla si funciona o no la web y es scrapeable\n",
    "        return response\n",
    "    else:\n",
    "        print(f\"request returned{response.status_code} error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cV7Mwt-Ai_Dk"
   },
   "outputs": [],
   "source": [
    "# url to scrape\n",
    "url = \"https://sandeepmj.github.io/scrape-example-page/pages.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## call the function\n",
    "response = mkRequest(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyHHqpmYi_Dk"
   },
   "source": [
    "## Turn page into soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create function to create soup\n",
    "def mkSoup (response):\n",
    "    '''\n",
    "    Make soup\n",
    "    '''\n",
    "    return BeautifulSoup (response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html lang=\"en\">\n",
       "<head>\n",
       "<!-- Makes the page responsive and scaled to be read easily -->\n",
       "<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
       "<!-- Links to stylesheet -->\n",
       "<link href=\"style.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
       "<!-- Remember to update page title -->\n",
       "<title>List of Documents</title>\n",
       "</head>\n",
       "<body>\n",
       "<!-- All content goes here -->\n",
       "<div class=\"container\">\n",
       "<h1>Documents to Download</h1>\n",
       "<li>Junk Li <a href=\"\">tag 1</a></li>\n",
       "<li>Junk Li <a href=\"\">tag 2</a></li>\n",
       "<ul class=\"txts downloadable\">\n",
       "<p class=\"pages\">Download this first set of text documents</p>\n",
       "<li>Text Document <a href=\"files/text_doc_01.txt\">1</a> </li>\n",
       "<li>Text Document <a href=\"files/text_doc_02.txt\">2</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_03.txt\">3</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_04.txt\">4</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_05.txt\">5</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_06.txt\">6</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_07.txt\">7</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_08.txt\">8</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_09.txt\">9</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_10.txt\">10</a></li>\n",
       "</ul>\n",
       "<li>Junk Li <a href=\"\">tag 3</a></li>\n",
       "<li>Junk Li <a href=\"\">tag 4</a></li>\n",
       "<ul class=\"pdfs downloadable\">\n",
       "<p class=\"pages\">Download this list of PDFs</p>\n",
       "<li>PDF Document <a href=\"files/pdf_1.pdf\">1</a> </li>\n",
       "<li>PDF Document <a href=\"files/pdf_2.pdf\">2</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_3.pdf\">3</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_4.pdf\">4</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_5.pdf\">5</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_6.pdf\">6</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_7.pdf\">7</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_8.pdf\">8</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_9.pdf\">9</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_10.pdf\">10</a></li>\n",
       "</ul>\n",
       "<li>Junk Li <a href=\"\">tag 5</a></li>\n",
       "<li>Junk Li <a href=\"\">tag 6</a></li>\n",
       "<ul class=\"txts downloadable\">\n",
       "<p class=\"pages\">Download this second set of text documents</p>\n",
       "<li>Text Document <a href=\"files/text_doc_A.txt\">1</a> </li>\n",
       "<li>Text Document <a href=\"files/text_doc_B.txt\">2</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_C.txt\">3</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_D.txt\">4</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_E.txt\">5</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_F.txt\">6</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_G.txt\">7</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_H.txt\">8</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_I.txt\">9</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_J.txt\">10</a></li>\n",
       "</ul>\n",
       "</div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## call the function\n",
    "soup = mkSoup(response)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MC function (Master of ceremony. Nombre informal de Sandeep)\n",
    "def scraper (url):\n",
    "    '''\n",
    "    Enter url to return soup of page\n",
    "    '''\n",
    "    return mkSoup(mkRequest(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html lang=\"en\">\n",
       "<head>\n",
       "<!-- Makes the page responsive and scaled to be read easily -->\n",
       "<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
       "<!-- Links to stylesheet -->\n",
       "<link href=\"style.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
       "<!-- Remember to update page title -->\n",
       "<title>List of Documents</title>\n",
       "</head>\n",
       "<body>\n",
       "<!-- All content goes here -->\n",
       "<div class=\"container\">\n",
       "<h1>Documents to Download</h1>\n",
       "<li>Junk Li <a href=\"\">tag 1</a></li>\n",
       "<li>Junk Li <a href=\"\">tag 2</a></li>\n",
       "<ul class=\"txts downloadable\">\n",
       "<p class=\"pages\">Download this first set of text documents</p>\n",
       "<li>Text Document <a href=\"files/text_doc_01.txt\">1</a> </li>\n",
       "<li>Text Document <a href=\"files/text_doc_02.txt\">2</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_03.txt\">3</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_04.txt\">4</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_05.txt\">5</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_06.txt\">6</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_07.txt\">7</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_08.txt\">8</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_09.txt\">9</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_10.txt\">10</a></li>\n",
       "</ul>\n",
       "<li>Junk Li <a href=\"\">tag 3</a></li>\n",
       "<li>Junk Li <a href=\"\">tag 4</a></li>\n",
       "<ul class=\"pdfs downloadable\">\n",
       "<p class=\"pages\">Download this list of PDFs</p>\n",
       "<li>PDF Document <a href=\"files/pdf_1.pdf\">1</a> </li>\n",
       "<li>PDF Document <a href=\"files/pdf_2.pdf\">2</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_3.pdf\">3</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_4.pdf\">4</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_5.pdf\">5</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_6.pdf\">6</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_7.pdf\">7</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_8.pdf\">8</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_9.pdf\">9</a></li>\n",
       "<li>PDF Document <a href=\"files/pdf_10.pdf\">10</a></li>\n",
       "</ul>\n",
       "<li>Junk Li <a href=\"\">tag 5</a></li>\n",
       "<li>Junk Li <a href=\"\">tag 6</a></li>\n",
       "<ul class=\"txts downloadable\">\n",
       "<p class=\"pages\">Download this second set of text documents</p>\n",
       "<li>Text Document <a href=\"files/text_doc_A.txt\">1</a> </li>\n",
       "<li>Text Document <a href=\"files/text_doc_B.txt\">2</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_C.txt\">3</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_D.txt\">4</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_E.txt\">5</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_F.txt\">6</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_G.txt\">7</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_H.txt\">8</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_I.txt\">9</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_J.txt\">10</a></li>\n",
       "</ul>\n",
       "</div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = scraper(url)\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z42CN1eKi_Dk"
   },
   "source": [
    "## Find all txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "l5GhvRuji_Dl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"files/text_doc_01.txt\">1</a>,\n",
       " <a href=\"files/text_doc_02.txt\">2</a>,\n",
       " <a href=\"files/text_doc_03.txt\">3</a>,\n",
       " <a href=\"files/text_doc_04.txt\">4</a>,\n",
       " <a href=\"files/text_doc_05.txt\">5</a>,\n",
       " <a href=\"files/text_doc_06.txt\">6</a>,\n",
       " <a href=\"files/text_doc_07.txt\">7</a>,\n",
       " <a href=\"files/text_doc_08.txt\">8</a>,\n",
       " <a href=\"files/text_doc_09.txt\">9</a>,\n",
       " <a href=\"files/text_doc_10.txt\">10</a>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## save in list called txt_holder\n",
    "aTags = soup.find(\"ul\", class_ = \"txts\").find_all(\"a\")\n",
    "aTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## what type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8sCo7syi_Dl"
   },
   "source": [
    "## Find all the ```a``` tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "1BBjQWqsi_Dl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"files/text_doc_01.txt\">1</a>,\n",
       " <a href=\"files/text_doc_02.txt\">2</a>,\n",
       " <a href=\"files/text_doc_03.txt\">3</a>,\n",
       " <a href=\"files/text_doc_04.txt\">4</a>,\n",
       " <a href=\"files/text_doc_05.txt\">5</a>,\n",
       " <a href=\"files/text_doc_06.txt\">6</a>,\n",
       " <a href=\"files/text_doc_07.txt\">7</a>,\n",
       " <a href=\"files/text_doc_08.txt\">8</a>,\n",
       " <a href=\"files/text_doc_09.txt\">9</a>,\n",
       " <a href=\"files/text_doc_10.txt\">10</a>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## target a tags\n",
    "aTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "BR4K5BkGi_Dm"
   },
   "outputs": [],
   "source": [
    "## base url\n",
    "base_url = \"https://sandeepmj.github.io/scrape-example-page/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "UPgFpi0ui_Dl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://sandeepmj.github.io/scrape-example-page/files/text_doc_01.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_02.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_03.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_04.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_05.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_06.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_07.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_08.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_09.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_10.txt']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## save without html using for loop\n",
    "links = [base_url + aTag.get(\"href\") for aTag in aTags]\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save without html using list comprehension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3Sv-zUhi_Dm"
   },
   "source": [
    "## What is missing from the URLs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8sgMa05i_Dm"
   },
   "source": [
    "## Create a list of the full URLs\n",
    "\n",
    "Without all the ```html```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "VOJEvd2ki_Dm"
   },
   "outputs": [],
   "source": [
    "## lc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCqmE0y6i_Dm"
   },
   "source": [
    "## Download all the ```txt``` documents\n",
    "\n",
    "pip install wget, a great utility to download from links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9680 sha256=a1d48fa3ee14711490e498397cefdece88d7c8efe75559e9fa7d0d900d70081f\n",
      "  Stored in directory: /Users/patxiuranga/Library/Caches/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import wget\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make timer function\n",
    "def snoozer (start_range, end_range):\n",
    "    snooze_time = randrange(start_range,end_range)\n",
    "    print(f\" \\n Snoozing for {snooze_time} seconds\")\n",
    "    return time.sleep(snooze_time) # sin esta línea, no duerme el programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Snoozing for 5 seconds\n"
     ]
    }
   ],
   "source": [
    "snoozer(5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading link 1 of 10\n",
      " \n",
      " Snoozing for 14 seconds\n",
      "Downloading link 2 of 10\n",
      " \n",
      " Snoozing for 17 seconds\n",
      "Downloading link 3 of 10\n",
      " \n",
      " Snoozing for 12 seconds\n",
      "Downloading link 4 of 10\n",
      " \n",
      " Snoozing for 17 seconds\n",
      "Downloading link 5 of 10\n",
      " \n",
      " Snoozing for 11 seconds\n",
      "Downloading link 6 of 10\n",
      " \n",
      " Snoozing for 10 seconds\n",
      "Downloading link 7 of 10\n",
      " \n",
      " Snoozing for 10 seconds\n",
      "Downloading link 8 of 10\n",
      " \n",
      " Snoozing for 20 seconds\n",
      "Downloading link 9 of 10\n",
      " \n",
      " Snoozing for 15 seconds\n",
      "Downloading link 10 of 10\n",
      " \n",
      " Snoozing for 16 seconds\n"
     ]
    }
   ],
   "source": [
    "## download with timer\n",
    "link_count = 1\n",
    "start_range, end_range = 10, 21\n",
    "for link in links:\n",
    "    print(f\"Downloading link {link_count} of {len(links)}\")\n",
    "    link_count +=1\n",
    "    wget.download(link)\n",
    "    snoozer(start_range, end_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all text files\n",
    "\n",
    "\n",
    "all_text = soup.find_all(\"ul\", class_=\"txts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "aTag_list = []\n",
    "for atag in all_text:\n",
    "    aTag_list.append(atag.find_all(\"a\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<a href=\"files/text_doc_01.txt\">1</a>,\n",
       "  <a href=\"files/text_doc_02.txt\">2</a>,\n",
       "  <a href=\"files/text_doc_03.txt\">3</a>,\n",
       "  <a href=\"files/text_doc_04.txt\">4</a>,\n",
       "  <a href=\"files/text_doc_05.txt\">5</a>,\n",
       "  <a href=\"files/text_doc_06.txt\">6</a>,\n",
       "  <a href=\"files/text_doc_07.txt\">7</a>,\n",
       "  <a href=\"files/text_doc_08.txt\">8</a>,\n",
       "  <a href=\"files/text_doc_09.txt\">9</a>,\n",
       "  <a href=\"files/text_doc_10.txt\">10</a>],\n",
       " [<a href=\"files/text_doc_A.txt\">1</a>,\n",
       "  <a href=\"files/text_doc_B.txt\">2</a>,\n",
       "  <a href=\"files/text_doc_C.txt\">3</a>,\n",
       "  <a href=\"files/text_doc_D.txt\">4</a>,\n",
       "  <a href=\"files/text_doc_E.txt\">5</a>,\n",
       "  <a href=\"files/text_doc_F.txt\">6</a>,\n",
       "  <a href=\"files/text_doc_G.txt\">7</a>,\n",
       "  <a href=\"files/text_doc_H.txt\">8</a>,\n",
       "  <a href=\"files/text_doc_I.txt\">9</a>,\n",
       "  <a href=\"files/text_doc_J.txt\">10</a>]]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aTag_list #Estan nested (lista en lista). Encadenados. Pero flat es mejor que nested. Tenemos que desencadenarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Así lo desencadeno\n",
    "flat_list = []\n",
    "for sub_list in aTag_list:\n",
    "    for item in sub_list:\n",
    "        flat_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"files/text_doc_01.txt\">1</a>,\n",
       " <a href=\"files/text_doc_02.txt\">2</a>,\n",
       " <a href=\"files/text_doc_03.txt\">3</a>,\n",
       " <a href=\"files/text_doc_04.txt\">4</a>,\n",
       " <a href=\"files/text_doc_05.txt\">5</a>,\n",
       " <a href=\"files/text_doc_06.txt\">6</a>,\n",
       " <a href=\"files/text_doc_07.txt\">7</a>,\n",
       " <a href=\"files/text_doc_08.txt\">8</a>,\n",
       " <a href=\"files/text_doc_09.txt\">9</a>,\n",
       " <a href=\"files/text_doc_10.txt\">10</a>,\n",
       " <a href=\"files/text_doc_A.txt\">1</a>,\n",
       " <a href=\"files/text_doc_B.txt\">2</a>,\n",
       " <a href=\"files/text_doc_C.txt\">3</a>,\n",
       " <a href=\"files/text_doc_D.txt\">4</a>,\n",
       " <a href=\"files/text_doc_E.txt\">5</a>,\n",
       " <a href=\"files/text_doc_F.txt\">6</a>,\n",
       " <a href=\"files/text_doc_G.txt\">7</a>,\n",
       " <a href=\"files/text_doc_H.txt\">8</a>,\n",
       " <a href=\"files/text_doc_I.txt\">9</a>,\n",
       " <a href=\"files/text_doc_J.txt\">10</a>]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#con itertools\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"files/text_doc_01.txt\">1</a>,\n",
       " <a href=\"files/text_doc_02.txt\">2</a>,\n",
       " <a href=\"files/text_doc_03.txt\">3</a>,\n",
       " <a href=\"files/text_doc_04.txt\">4</a>,\n",
       " <a href=\"files/text_doc_05.txt\">5</a>,\n",
       " <a href=\"files/text_doc_06.txt\">6</a>,\n",
       " <a href=\"files/text_doc_07.txt\">7</a>,\n",
       " <a href=\"files/text_doc_08.txt\">8</a>,\n",
       " <a href=\"files/text_doc_09.txt\">9</a>,\n",
       " <a href=\"files/text_doc_10.txt\">10</a>,\n",
       " <a href=\"files/text_doc_A.txt\">1</a>,\n",
       " <a href=\"files/text_doc_B.txt\">2</a>,\n",
       " <a href=\"files/text_doc_C.txt\">3</a>,\n",
       " <a href=\"files/text_doc_D.txt\">4</a>,\n",
       " <a href=\"files/text_doc_E.txt\">5</a>,\n",
       " <a href=\"files/text_doc_F.txt\">6</a>,\n",
       " <a href=\"files/text_doc_G.txt\">7</a>,\n",
       " <a href=\"files/text_doc_H.txt\">8</a>,\n",
       " <a href=\"files/text_doc_I.txt\">9</a>,\n",
       " <a href=\"files/text_doc_J.txt\">10</a>]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_links = list(itertools.chain(*aTag_list)) \n",
    "html_links\n",
    "# El asterisco indica que tengo que tomar cada elemento de la lista por separado (y encadenarlo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "week-7-download_docs_BLANK.ipynb",
   "provenance": [
    {
     "file_id": "1nqLLwMBVA4UJus95SFvmBL-GsFXxpcsW",
     "timestamp": 1638974922793
    },
    {
     "file_id": "1J1lhUQakLF4NmWxBeEGiprUMSv1j7cpk",
     "timestamp": 1628019785208
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
