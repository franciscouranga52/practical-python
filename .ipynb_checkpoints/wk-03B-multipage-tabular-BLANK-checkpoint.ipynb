{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rg5ypHYQ2vB"
   },
   "source": [
    "# Multi-page Tables Scrape Demo\n",
    "\n",
    "You're often going to encounter data and tables spread across hundreds if not thousands of pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLy-Ml41_-Zd"
   },
   "source": [
    "We might want to, for example, compile details about all the doctors  <a href=\"https://apps.health.ny.gov/pubdoh/professionals/doctors/conduct/factions/AllRecordsAction.action\">on this site</a> and export to a ```dataframe``` and a ```.csv``` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FAa4EkaQ2vH"
   },
   "source": [
    "#### Today in class\n",
    "\n",
    "We're going to scrape as a demo a table that runs across several pages on [this mock website](https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page1.html).\n",
    "\n",
    "```https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page1.html```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTY4tDkVQ2vI"
   },
   "source": [
    "To capture your target information into a single CSV file will require the use of many of the foundational skills we've covered, including:\n",
    "\n",
    "- ```delays```\n",
    "- ```conditional logic```\n",
    "- ```for loops```\n",
    "\n",
    "\n",
    "And we'll explore a few new functional Python methods today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzHxjNFUQ2vI"
   },
   "source": [
    "## Scraping Strategies\n",
    "\n",
    "- How do we approach this scrape?\n",
    "- What pattern do we see?\n",
    "- How do we capture a table on a single page?\n",
    "- How do we capture a sequence of tables?\n",
    "- How we navigate from page 1 to the subsequent pages?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9IgexKhQ2vJ"
   },
   "source": [
    "# Let's code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tZ7ZNO8YQ2vJ"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wl2yMzxEQ2vK"
   },
   "source": [
    "## Single Table Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "L3eCtCpJQ2vK"
   },
   "outputs": [],
   "source": [
    "##scrape url website\n",
    "url = \"https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page1.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PShccOFp4Xg7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## page content type\n",
    "type(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "OEbE38UkHkxb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## page text type\n",
    "type(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html lang=\"en\">\\n\\n\\t<head>\\n\\n\\t\\t<!-- Makes the page responsive and scaled to be read easily -->\\n\\t\\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n\\n\\t\\t<!-- Links to stylesheet -->\\n\\t\\t<link rel=\"stylesheet\" type=\"text/css\" href=\"style.css\">\\n\\t\\t<!-- Remember to update page title -->\\n\\t\\t<title>Heaviest Animals</title>\\n\\n\\t</head>\\n\\n\\t<body>\\n\\t\\t<!-- All content goes here -->\\n\\n\\t\\t<div class=\"container\">\\n\\t\\t\\t<section id=\"multi_table\">\\n\\t\\t\\t\\t<table class=\"full_table\">\\n\\t\\t\\t\\t\\t<h3>20 Heaviest Animals in the World</h3>\\n\\t\\t\\t\\t\\t<h4>Showing 1-5 of 20</h4>\\n\\t\\t\\t\\t\\t<thead>\\n\\t\\t\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t\\t\\t\\t<th class=\"table-head\">Animal</th>\\n\\t\\t\\t\\t\\t\\t\\t<th class=\"table-head\">Weight(kg)</th>\\n\\t\\t\\t\\t\\t\\t\\t<th class=\"table-head\">Type</th>\\n\\t\\t\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\t</thead>\\n\\t\\t\\t\\t\\t<tbody>\\n\\t\\t\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t\\t\\t\\t<td>Blue whale</td>\\n\\t\\t\\t\\t\\t\\t\\t<td>136,000</td>\\n\\t\\t\\t\\t\\t\\t\\t<td>Marine</td>\\n\\n\\t\\t\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t\\t\\t\\t<td>Bowhead whale</td>\\n\\t\\t\\t\\t\\t\\t\\t<td>100,000</td>\\n\\t\\t\\t\\t\\t\\t\\t<td>Marine</td>\\n\\n\\t\\t\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t\\t\\t\\t<td>Fin whale</td>\\n\\t\\t\\t\\t\\t\\t\\t<td>70,000</td>\\n\\t\\t\\t\\t\\t\\t\\t<td>Marine</td>\\n\\n\\t\\t\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t\\t\\t\\t<td>Southern right whale</td>\\n\\t\\t\\t\\t\\t\\t\\t<td>45,000</td>\\n\\t\\t\\t\\t\\t\\t\\t<td>Marine</td>\\n\\n\\t\\t\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\t\\t<tr>\\n\\t\\t\\t\\t\\t\\t\\t<td>Humpback whale</td>\\n\\t\\t\\t\\t\\t\\t\\t<td>30,000</td>\\n\\t\\t\\t\\t\\t\\t\\t<td>Marine</td>\\n\\n\\t\\t\\t\\t\\t\\t</tr>\\n\\t\\t\\t\\t\\t</tbody>\\n\\t\\t\\t\\t</table>\\n\\n\\t\\t\\t</section>\\n\\n\\t\\t\\t<div class=\"pagination\">\\n\\t\\t\\t\\t<a href=\"#\">&laquo;</a>\\n\\t\\t\\t\\t<a href=\"#\">1</a>\\n\\t\\t\\t\\t<a href=\"heaviest-animals-page2.html\">2</a>\\n\\t\\t\\t\\t<a href=\"heaviest-animals-page3.html\">3</a>\\n\\t\\t\\t\\t<a href=\"heaviest-animals-page4.html\">4</a>\\n\\t\\t\\t\\t<a href=\"heaviest-animals-page5.html\">5</a>\\n\\n\\t\\t\\t\\t<a href=\"heaviest-animals-page2.html\">&raquo;</a>\\n\\t\\t\\t</div>\\n\\n\\t\\t</div>\\n\\n\\n\\t</body>\\n\\n</html>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lq7Fxh77KLU8"
   },
   "source": [
    "## ```Pandas``` captures tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "gh83GGbyQ2vL"
   },
   "outputs": [],
   "source": [
    "## use Pandas to read tables on page\n",
    "df1 = pd.read_html(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                 Animal  Weight(kg)    Type\n",
       " 0            Blue whale      136000  Marine\n",
       " 1         Bowhead whale      100000  Marine\n",
       " 2             Fin whale       70000  Marine\n",
       " 3  Southern right whale       45000  Marine\n",
       " 4        Humpback whale       30000  Marine]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "MvtGiiY7Q2vL"
   },
   "outputs": [],
   "source": [
    "## Do we want the first table?\n",
    "df = df1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal</th>\n",
       "      <th>Weight(kg)</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blue whale</td>\n",
       "      <td>136000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bowhead whale</td>\n",
       "      <td>100000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fin whale</td>\n",
       "      <td>70000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Southern right whale</td>\n",
       "      <td>45000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Humpback whale</td>\n",
       "      <td>30000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Animal  Weight(kg)    Type\n",
       "0            Blue whale      136000  Marine\n",
       "1         Bowhead whale      100000  Marine\n",
       "2             Fin whale       70000  Marine\n",
       "3  Southern right whale       45000  Marine\n",
       "4        Humpback whale       30000  Marine"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dXIYAPPqQ2vL"
   },
   "outputs": [],
   "source": [
    "## store it into a copy called animals_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gheKHsbiQ2vM"
   },
   "source": [
    "## But we want to scrape multiple pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "euCu3yvc6GsF"
   },
   "outputs": [],
   "source": [
    "## Never do this manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46_dtNz43Cb8"
   },
   "source": [
    "## ```f-strings``` to create our links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "e8hJx1nSQ2vO"
   },
   "outputs": [],
   "source": [
    "## base url of site to scrape\n",
    "base_url = \"https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "JGQMfxyrQ2vO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page1.html',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page2.html',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page3.html',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page4.html',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page5.html']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using a ```for loop```\n",
    "urls_fl = []\n",
    "for url_number in range(1,6):\n",
    "    #print(f\"{base_url}{url_number}.html\")\n",
    "    urls_fl.append(f\"{base_url}{url_number}.html\")\n",
    "urls_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "-WbAbHYLVcfX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page1.html',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page2.html',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page3.html',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page4.html',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page5.html']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using list comprehension\n",
    "urls_lc = [(f\"{base_url}{url_number}.html\") for url_number in range(1,6)]\n",
    "urls_lc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_oDySdwQ2vO"
   },
   "source": [
    "## Back to our scrape\n",
    "\n",
    "Remember, we'll hit this server too fast. We have to add a delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "RyDiu5HVQ2vQ"
   },
   "outputs": [],
   "source": [
    "## Let's import the required libaries to create a delay\n",
    "from random import randrange\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "4_Pl33BnuGck"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping 1 of 5\n",
      "                 Animal  Weight(kg)    Type\n",
      "0            Blue whale      136000  Marine\n",
      "1         Bowhead whale      100000  Marine\n",
      "2             Fin whale       70000  Marine\n",
      "3  Southern right whale       45000  Marine\n",
      "4        Humpback whale       30000  Marine\n",
      "Snoozing for 11 seconds before next scrape\n",
      "Scrapping 2 of 5\n",
      "                 Animal  Weight(kg)    Type\n",
      "0            Gray whale       28500  Marine\n",
      "1  Northern right whale       23000  Marine\n",
      "2             Sei whale       20000  Marine\n",
      "3         Bryde's whale       16000  Marine\n",
      "4  Baird's beaked whale       11380  Marine\n",
      "Snoozing for 8 seconds before next scrape\n",
      "Scrapping 3 of 5\n",
      "                      Animal  Weight(kg)         Type\n",
      "0                Minke whale        7500       Marine\n",
      "1  Northern bottlenose whale        6500       Marine\n",
      "2     Gervais's beaked whale        5600       Marine\n",
      "3           African elephant        4800  Terrestrial\n",
      "4               Killer whale        3988       Marine\n",
      "Snoozing for 10 seconds before next scrape\n",
      "Scrapping 4 of 5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No tables found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-31d5c131c972>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msnoozer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m                 )\n\u001b[1;32m    298\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only)\u001b[0m\n\u001b[1;32m   1083\u001b[0m     \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m     return _parse(\n\u001b[0m\u001b[1;32m   1086\u001b[0m         \u001b[0mflavor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflavor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m         \u001b[0mio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, **kwargs)\u001b[0m\n\u001b[1;32m    911\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mretained\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# for mypy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mretained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, **kwargs)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m             \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcaught\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0;31m# if `io` is an io-like object, check if it's seekable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36mparse_tables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mparsed\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfooter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mtuples\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \"\"\"\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_thead_tbody_tfoot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse_tables\u001b[0;34m(self, doc, match, attrs)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No tables found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No tables found"
     ]
    }
   ],
   "source": [
    "## first time scrape\n",
    "# agrego algunas variables para monitorear el avance\n",
    "total_links = len(urls_lc) \n",
    "counter = 1 \n",
    "for url in urls_lc:\n",
    "    print(f\"Scrapping {counter} of {total_links}\")\n",
    "    counter += 1\n",
    "    response = requests.get(url)\n",
    "    df = pd.read_html(response.text)[0]\n",
    "    print(df)\n",
    "    snoozer = randrange(5,12)\n",
    "    print(f\"Snoozing for {snoozer} seconds before next scrape\")\n",
    "    time.sleep(snoozer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "25AH8Ema5FT9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## what was our status code when it broke? Dio error porque una de las url daba error (404)\n",
    "## chequeamos el último resultado en response (el que quedó guardado en la variable)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uPWDrxJQ2vQ"
   },
   "source": [
    "## Working Around Errors\n",
    "\n",
    "When you scrape hundreds of pages, there's chance that one of the URLs might be a dud.\n",
    "\n",
    "We can set up a error control to see what kind of responses we get:\n",
    "\n",
    "```<Response [200]>``` means website is accessible.\n",
    "\n",
    "```<Response [404]>``` means broken link or no page on content.\n",
    "\n",
    "In that case, your whole code might break and you'll have to figure out where it broke.\n",
    "\n",
    "We can make that easier with ```Conditional Logic``` or ```Error Exceptions```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CO50-gA84tMe"
   },
   "source": [
    "### Bypassing exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "25bbP3YKvYQy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping 1 of 5\n",
      "                 Animal  Weight(kg)    Type\n",
      "0            Blue whale      136000  Marine\n",
      "1         Bowhead whale      100000  Marine\n",
      "2             Fin whale       70000  Marine\n",
      "3  Southern right whale       45000  Marine\n",
      "4        Humpback whale       30000  Marine\n",
      "Snoozing for 10 seconds before next scrape\n",
      "Scrapping 2 of 5\n",
      "                 Animal  Weight(kg)    Type\n",
      "0            Gray whale       28500  Marine\n",
      "1  Northern right whale       23000  Marine\n",
      "2             Sei whale       20000  Marine\n",
      "3         Bryde's whale       16000  Marine\n",
      "4  Baird's beaked whale       11380  Marine\n",
      "Snoozing for 9 seconds before next scrape\n",
      "Scrapping 3 of 5\n",
      "                      Animal  Weight(kg)         Type\n",
      "0                Minke whale        7500       Marine\n",
      "1  Northern bottlenose whale        6500       Marine\n",
      "2     Gervais's beaked whale        5600       Marine\n",
      "3           African elephant        4800  Terrestrial\n",
      "4               Killer whale        3988       Marine\n",
      "Snoozing for 5 seconds before next scrape\n",
      "Scrapping 4 of 5\n",
      "oh no, https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page4.html returned 404\n",
      "Snoozing for 5 seconds before next scrape\n",
      "Scrapping 5 of 5\n",
      "                     Animal  Weight(kg)         Type\n",
      "0              Hippopotamus        3750  Terrestrial\n",
      "1            Asian elephant        3178  Terrestrial\n",
      "2     Cuvier's beaked whale        2701       Marine\n",
      "3  Short-finned pilot whale        2200       Marine\n",
      "4          White rhinoceros        2175  Terrestrial\n",
      "Snoozing for 10 seconds before next scrape\n",
      "Done scrapping all provided links\n"
     ]
    }
   ],
   "source": [
    "## deal with exceptions\n",
    "## hold on to broken links \n",
    "busted_links = [] #links rotos\n",
    "df_all = [] #pone todos los df en una lista\n",
    "total_links = len(urls_lc)\n",
    "counter = 1 \n",
    "\n",
    "for url in urls_lc:\n",
    "    print(f\"Scrapping {counter} of {total_links}\")\n",
    "    counter += 1\n",
    "    response = requests.get(url)\n",
    "    try:  \n",
    "        df = pd.read_html(response.text)[0]\n",
    "    except:\n",
    "        print(f\"Oh no, {url} returned {response.status_code}\")\n",
    "        busted_links.append(url)\n",
    "    else:\n",
    "        df_all.append(df) # cada página crea un dataframe y lo agrego a esta lista\n",
    "        print(df)\n",
    "    snoozer = randrange(5,12)\n",
    "    print(f\"Snoozing for {snoozer} seconds before next scrape\")\n",
    "    time.sleep(snoozer)\n",
    "print(\"Done scrapping all provided links\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "DQ1-n--sQH9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://sandeepmj.github.io/scrape-example-page/heaviest-animals-page4.html']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## which link broke?\n",
    "busted_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "a_qXuB6dQkWn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                 Animal  Weight(kg)    Type\n",
       " 0            Blue whale      136000  Marine\n",
       " 1         Bowhead whale      100000  Marine\n",
       " 2             Fin whale       70000  Marine\n",
       " 3  Southern right whale       45000  Marine\n",
       " 4        Humpback whale       30000  Marine,\n",
       "                  Animal  Weight(kg)    Type\n",
       " 0            Gray whale       28500  Marine\n",
       " 1  Northern right whale       23000  Marine\n",
       " 2             Sei whale       20000  Marine\n",
       " 3         Bryde's whale       16000  Marine\n",
       " 4  Baird's beaked whale       11380  Marine,\n",
       "                       Animal  Weight(kg)         Type\n",
       " 0                Minke whale        7500       Marine\n",
       " 1  Northern bottlenose whale        6500       Marine\n",
       " 2     Gervais's beaked whale        5600       Marine\n",
       " 3           African elephant        4800  Terrestrial\n",
       " 4               Killer whale        3988       Marine,\n",
       "                      Animal  Weight(kg)         Type\n",
       " 0              Hippopotamus        3750  Terrestrial\n",
       " 1            Asian elephant        3178  Terrestrial\n",
       " 2     Cuvier's beaked whale        2701       Marine\n",
       " 3  Short-finned pilot whale        2200       Marine\n",
       " 4          White rhinoceros        2175  Terrestrial]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## what does df_all hold?\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "cadFBbKfxoGg"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal</th>\n",
       "      <th>Weight(kg)</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blue whale</td>\n",
       "      <td>136000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bowhead whale</td>\n",
       "      <td>100000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fin whale</td>\n",
       "      <td>70000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Southern right whale</td>\n",
       "      <td>45000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Humpback whale</td>\n",
       "      <td>30000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gray whale</td>\n",
       "      <td>28500</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Northern right whale</td>\n",
       "      <td>23000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sei whale</td>\n",
       "      <td>20000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bryde's whale</td>\n",
       "      <td>16000</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baird's beaked whale</td>\n",
       "      <td>11380</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Minke whale</td>\n",
       "      <td>7500</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Northern bottlenose whale</td>\n",
       "      <td>6500</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Gervais's beaked whale</td>\n",
       "      <td>5600</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>African elephant</td>\n",
       "      <td>4800</td>\n",
       "      <td>Terrestrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Killer whale</td>\n",
       "      <td>3988</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Hippopotamus</td>\n",
       "      <td>3750</td>\n",
       "      <td>Terrestrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Asian elephant</td>\n",
       "      <td>3178</td>\n",
       "      <td>Terrestrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cuvier's beaked whale</td>\n",
       "      <td>2701</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Short-finned pilot whale</td>\n",
       "      <td>2200</td>\n",
       "      <td>Marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>White rhinoceros</td>\n",
       "      <td>2175</td>\n",
       "      <td>Terrestrial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Animal  Weight(kg)         Type\n",
       "0                  Blue whale      136000       Marine\n",
       "1               Bowhead whale      100000       Marine\n",
       "2                   Fin whale       70000       Marine\n",
       "3        Southern right whale       45000       Marine\n",
       "4              Humpback whale       30000       Marine\n",
       "5                  Gray whale       28500       Marine\n",
       "6        Northern right whale       23000       Marine\n",
       "7                   Sei whale       20000       Marine\n",
       "8               Bryde's whale       16000       Marine\n",
       "9        Baird's beaked whale       11380       Marine\n",
       "10                Minke whale        7500       Marine\n",
       "11  Northern bottlenose whale        6500       Marine\n",
       "12     Gervais's beaked whale        5600       Marine\n",
       "13           African elephant        4800  Terrestrial\n",
       "14               Killer whale        3988       Marine\n",
       "15               Hippopotamus        3750  Terrestrial\n",
       "16             Asian elephant        3178  Terrestrial\n",
       "17      Cuvier's beaked whale        2701       Marine\n",
       "18   Short-finned pilot whale        2200       Marine\n",
       "19           White rhinoceros        2175  Terrestrial"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## convert to a single df rather than a list of df\n",
    "df = pd.concat(df_all, ignore_index = True) #el ignore es para evitar que se repitan los ID\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "AsXNgC9G56a1"
   },
   "outputs": [],
   "source": [
    "## export to csv\n",
    "df.to_csv(\"heaviest_animals.csv\", index = False, encoding = \"UTF-8\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "provenance": [
    {
     "file_id": "133K0NfwJ7esE3C-1QJ87ioTys44QdCLg",
     "timestamp": 1686746316714
    },
    {
     "file_id": "1LoyGXck4gm9F5OCk8k8YnltY-qlS7IR2",
     "timestamp": 1686738505513
    },
    {
     "file_id": "19JXSG8YXI8ZeNhzg8eaosuUkNaOp0xul",
     "timestamp": 1649162440933
    },
    {
     "file_id": "1KakOxScjK7egFn3ooKIf7Rb6ZUXqQgxK",
     "timestamp": 1645576583652
    },
    {
     "file_id": "1z2FLWwyi08NbTWdTLDEvMFbVIUWVuA7P",
     "timestamp": 1627431398775
    },
    {
     "file_id": "1VYOVnnddMwivH0B0hVpZswz7cKoEAfh-",
     "timestamp": 1627392451278
    },
    {
     "file_id": "1l6IbXo8xXwYbyNHHaNoH7QP3ssh_xrKq",
     "timestamp": 1619610819329
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
